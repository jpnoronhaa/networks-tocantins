{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a08b7dda-38c6-4321-8674-fa4ecc1856ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import powerlaw\n",
    "from scipy import stats\n",
    "from scipy.stats import weibull_min, poisson\n",
    "import os\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "from mpmath import zeta as mp_zeta\n",
    "\n",
    "INSTITUICOES = ['uft', 'ufnt', 'ceulp', 'ifto', 'unitins', 'tocantins']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9dc60b1b-4327-48cf-92e8-0915d13d04ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zeta(s, k_min=1):\n",
    "    \"\"\"Função zeta de Riemann truncada para cálculo da Power Law discreta\"\"\"\n",
    "    return float(mp_zeta(s, k_min))\n",
    "\n",
    "def weibull_loglik(data, params):\n",
    "    \"\"\"Calcula o log-likelihood para distribuição Weibull\"\"\"\n",
    "    return np.sum(weibull_min.logpdf(data, params['shape'], 0, params['scale']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b63602cc-052d-4763-9047-a9f051c83263",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_distributions(degree_values):\n",
    "    \"\"\"Realiza o ajuste e comparação de todas as distribuições\"\"\"\n",
    "    fit = powerlaw.Fit(degree_values, discrete=True)\n",
    "    shape, loc, scale = weibull_min.fit(degree_values, floc=0)\n",
    "    weibull_params = {'shape': shape, 'scale': scale}\n",
    "    mu = np.mean(degree_values)\n",
    "    poisson_params = {'mu': mu}\n",
    "    \n",
    "    k_values = np.array(degree_values)\n",
    "    k_min = fit.power_law.xmin\n",
    "    n = len(k_values[k_values >= k_min])\n",
    "    \n",
    "    # 1. Cálculo para Power Law (Lei de Potência)\n",
    "    alpha = fit.power_law.alpha\n",
    "    loglik_powerlaw = -n * np.log(zeta(alpha, k_min)) - alpha * np.sum(np.log(k_values[k_values >= k_min]))\n",
    "    \n",
    "    # 2. Cálculo para Exponential\n",
    "    Lambda = fit.exponential.Lambda\n",
    "    loglik_exponential = n * np.log(Lambda) - Lambda * np.sum(k_values[k_values >= k_min])\n",
    "    \n",
    "    # 3. Cálculo para Lognormal\n",
    "    mu_ln = fit.lognormal.mu\n",
    "    sigma_ln = fit.lognormal.sigma\n",
    "    loglik_lognormal = np.sum(-(np.log(k_values[k_values >= k_min]) - mu_ln)**2 / (2 * sigma_ln**2) - \n",
    "                       np.log(k_values[k_values >= k_min] * sigma_ln * np.sqrt(2 * np.pi)))\n",
    "    \n",
    "    # 4. Weibull\n",
    "    loglik_weibull = weibull_loglik(k_values, weibull_params)\n",
    "    \n",
    "    # 5. Poisson\n",
    "    loglik_poisson = poisson.logpmf(k_values, poisson_params['mu']).sum()\n",
    "    \n",
    "    models = {\n",
    "        'Power Law': {\n",
    "            'loglik': loglik_powerlaw,\n",
    "            'params': 2,  # alpha e xmin\n",
    "            'alpha': alpha,\n",
    "            'xmin': k_min\n",
    "        },\n",
    "        'Exponential': {\n",
    "            'loglik': loglik_exponential,\n",
    "            'params': 1,  # Lambda\n",
    "            'Lambda': Lambda\n",
    "        },\n",
    "        'Lognormal': {\n",
    "            'loglik': loglik_lognormal,\n",
    "            'params': 2,  # mu e sigma\n",
    "            'mu': mu_ln,\n",
    "            'sigma': sigma_ln\n",
    "        },\n",
    "        'Weibull': {\n",
    "            'loglik': loglik_weibull,\n",
    "            'params': 2,  # shape e scale\n",
    "            'shape': weibull_params['shape'],\n",
    "            'scale': weibull_params['scale']\n",
    "        },\n",
    "        'Poisson': {\n",
    "            'loglik': loglik_poisson,\n",
    "            'params': 1,  # mu\n",
    "            'mu': poisson_params['mu']\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Calcular AIC e pesos de Akaike\n",
    "    results = []\n",
    "    for name, model in models.items():\n",
    "        aic = 2 * model['params'] - 2 * model['loglik']\n",
    "        results.append({\n",
    "            'Modelo': name,\n",
    "            'Log-Likelihood': model['loglik'],\n",
    "            'Parâmetros': model['params'],\n",
    "            'AIC': aic,\n",
    "            **{k: v for k, v in model.items() if k not in ['loglik', 'params']}\n",
    "        })\n",
    "    \n",
    "    results_df = pd.DataFrame(results).sort_values('AIC')\n",
    "    results_df['ΔAIC'] = results_df['AIC'] - results_df['AIC'].min()\n",
    "    results_df['Peso AIC'] = np.exp(-0.5 * results_df['ΔAIC'])\n",
    "    results_df['Peso AIC'] = results_df['Peso AIC'] / results_df['Peso AIC'].sum()\n",
    "    \n",
    "    return results_df, fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e22de3ac-d5b0-4ae6-ba9f-e8c0282c17d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_individual_distributions_seaborn(institution, degree_values, save_dir, fit, weibull_params, poisson_params):\n",
    "    \"\"\"\n",
    "    Plota cada distribuição ajustada em gráficos separados usando Seaborn,\n",
    "    com fontes maiores e sem títulos.\n",
    "    \"\"\"\n",
    "    sns.set_theme(\n",
    "        style=\"whitegrid\", \n",
    "        font='serif',\n",
    "        rc={'font.serif': ['Times New Roman']}\n",
    "    )\n",
    "    sns.set_context(\"talk\")\n",
    "\n",
    "    # Preparação dos dados\n",
    "    degree_counts = pd.Series(degree_values).value_counts().sort_index()\n",
    "    P_k = degree_counts / len(degree_values)\n",
    "    k_range = np.arange(min(degree_values), max(degree_values) + 1)\n",
    "\n",
    "    output_path = Path(save_dir) / institution\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    AXIS_LABEL_SIZE = 20\n",
    "    LEGEND_SIZE = 18\n",
    "\n",
    "    # --- 1. Gráfico da Lei de Potência ---\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    ax = sns.scatterplot(x=P_k.index, y=P_k.values, s=100, label='Dados Empíricos')\n",
    "    fit.power_law.plot_pdf(ax=ax, color='r', linestyle='--', \n",
    "                           label=f'Lei de Potência (α={fit.power_law.alpha:.2f})')\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_xlabel('Grau (k)', fontsize=AXIS_LABEL_SIZE)\n",
    "    ax.set_ylabel('Probabilidade P(k)', fontsize=AXIS_LABEL_SIZE)\n",
    "    ax.legend(fontsize=LEGEND_SIZE)\n",
    "    plt.savefig(output_path / f'{institution}_power_law.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    # --- 2. Gráfico da Distribuição Exponencial ---\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    ax = sns.scatterplot(x=P_k.index, y=P_k.values, s=100, label='Dados Empíricos')\n",
    "    fit.exponential.plot_pdf(ax=ax, color='g', linestyle=':', \n",
    "                             label=f'Exponencial (λ={fit.exponential.Lambda:.2f})')\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_xlabel('Grau (k)', fontsize=AXIS_LABEL_SIZE)\n",
    "    ax.set_ylabel('Probabilidade P(k)', fontsize=AXIS_LABEL_SIZE)\n",
    "    ax.legend(fontsize=LEGEND_SIZE)\n",
    "    plt.savefig(output_path / f'{institution}_exponential.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    # --- 3. Gráfico da Distribuição Lognormal ---\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    ax = sns.scatterplot(x=P_k.index, y=P_k.values, s=100, label='Dados Empíricos')\n",
    "    fit.lognormal.plot_pdf(ax=ax, color='b', linestyle='-.', \n",
    "                           label=f'Lognormal (μ={fit.lognormal.mu:.2f}, σ={fit.lognormal.sigma:.2f})')\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_xlabel('Grau (k)', fontsize=AXIS_LABEL_SIZE)\n",
    "    ax.set_ylabel('Probabilidade P(k)', fontsize=AXIS_LABEL_SIZE)\n",
    "    ax.legend(fontsize=LEGEND_SIZE)\n",
    "    plt.savefig(output_path / f'{institution}_lognormal.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    # --- 4. Gráfico da Distribuição Weibull ---\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.scatterplot(x=P_k.index, y=P_k.values, s=100, label='Dados Empíricos')\n",
    "    weibull_fit = weibull_min.pdf(k_range, weibull_params['shape'], 0, weibull_params['scale'])\n",
    "    ax = sns.lineplot(x=k_range, y=weibull_fit, color='m', linestyle='--', \n",
    "                      label=f'Weibull (λ={weibull_params[\"scale\"]:.2f}, β={weibull_params[\"shape\"]:.2f})')\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_xlabel('Grau (k)', fontsize=AXIS_LABEL_SIZE)\n",
    "    ax.set_ylabel('Probabilidade P(k)', fontsize=AXIS_LABEL_SIZE)\n",
    "    ax.legend(fontsize=LEGEND_SIZE)\n",
    "    plt.savefig(output_path / f'{institution}_weibull.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    # --- 5. Gráfico da Distribuição Poisson ---\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.scatterplot(x=P_k.index, y=P_k.values, s=100, label='Dados Empíricos')\n",
    "    poisson_fit = poisson.pmf(k_range, poisson_params['mu'])\n",
    "    ax = sns.lineplot(x=k_range, y=poisson_fit, color='c', linestyle='-', \n",
    "                      label=f'Poisson (μ={poisson_params[\"mu\"]:.2f})')\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_xlabel('Grau (k)', fontsize=AXIS_LABEL_SIZE)\n",
    "    ax.set_ylabel('Probabilidade P(k)', fontsize=AXIS_LABEL_SIZE)\n",
    "    ax.legend(fontsize=LEGEND_SIZE)\n",
    "    plt.savefig(output_path / f'{institution}_poisson.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6e869669-c49d-48b2-98c5-aa0187aeb37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_degree_distribution(institution, save_dir=None):\n",
    "    file_path = f'../results/metrics/{institution}/{institution}_2024.json'\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    degree_distribution = data['degree_distribution']\n",
    "    \n",
    "    df = pd.DataFrame(list(degree_distribution.items()), columns=['Grau', 'Frequência'])\n",
    "    df['Grau'] = pd.to_numeric(df['Grau'])\n",
    "    df = df.sort_values('Grau')\n",
    "\n",
    "    df = df[df['Frequência'] > 0]\n",
    "    \n",
    "    sns.set_theme(\n",
    "        style=\"whitegrid\", \n",
    "        font='serif',\n",
    "        rc={'font.serif': ['Times New Roman']}\n",
    "    )\n",
    "    sns.set_context(\"talk\")\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    ax = sns.histplot(x='Grau', weights='Frequência', data=df, \n",
    "                     discrete=True, stat='count', alpha=0.7)\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_ylim(bottom=1)\n",
    "    ax.tick_params(labelsize=12)\n",
    "    ax.set_xlabel('Grau do Vértice', fontsize=14)\n",
    "    ax.set_ylabel('Número de Vértices (Frequência)', fontsize=14)\n",
    "    \n",
    "    plt.xticks(rotation=0, ha='right')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_dir:\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        save_path = Path(f'{save_dir}/{institution}/') / f'{institution}_degree_distribution.png'\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()\n",
    "    \n",
    "    # Extrair os valores de grau para os ajustes\n",
    "    degrees = data['degrees']\n",
    "    degree_values = [k for k in degrees.values() if k > 0]\n",
    "    \n",
    "    # Realizar a análise comparativa\n",
    "    results_df, fit = compare_distributions(degree_values)\n",
    "    \n",
    "    # Plotar os gráficos individuais para cada distribuição\n",
    "    if save_dir:\n",
    "        shape, loc, scale = weibull_min.fit(degree_values, floc=0)\n",
    "        weibull_params = {'shape': shape, 'scale': scale}\n",
    "        mu = np.mean(degree_values)\n",
    "        poisson_params = {'mu': mu}\n",
    "        \n",
    "        plot_individual_distributions_seaborn(institution, degree_values, save_dir, \n",
    "                                    fit, weibull_params, poisson_params)\n",
    "    \n",
    "    return results_df, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df53b2f1-3791-4451-879e-f153be576f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = \"../results/img/distribuicoes/\".strip()\n",
    "analysis_results = {}\n",
    "\n",
    "if save_dir and not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "# Processa cada instituição\n",
    "for instituicao in INSTITUICOES:\n",
    "    try:\n",
    "        print(f\"\\nProcessando {instituicao.upper()}...\")\n",
    "        results_df, data = plot_degree_distribution(instituicao, save_dir)\n",
    "        \n",
    "        # Armazenar resultados\n",
    "        analysis_results[instituicao] = {\n",
    "            'model_comparison': results_df,\n",
    "            'network_stats': {\n",
    "                'num_nodes': data['num_nodes'],\n",
    "                'num_edges': data['num_edges'],\n",
    "                'avg_degree': np.mean([k for k in data['degrees'].values() if k > 0]),\n",
    "                'max_degree': max(data['degrees'].values())\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Imprimir resultados\n",
    "        print(f\"\\nResultados para {instituicao.upper()}:\")\n",
    "        print(\"Comparação de Modelos:\")\n",
    "        print(results_df.to_markdown(tablefmt=\"grid\", floatfmt=\".2f\"))\n",
    "        \n",
    "        print(\"\\nEstatísticas da Rede:\")\n",
    "        print(f\"- Número de nós: {data['num_nodes']}\")\n",
    "        print(f\"- Número de arestas: {data['num_edges']}\")\n",
    "        print(f\"- Grau médio: {np.mean([k for k in data['degrees'].values() if k > 0]):.2f}\")\n",
    "        print(f\"- Grau máximo: {max(data['degrees'].values())}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao processar {instituicao}: {str(e)}\")\n",
    "\n",
    "print(\"\\nConcluído!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
