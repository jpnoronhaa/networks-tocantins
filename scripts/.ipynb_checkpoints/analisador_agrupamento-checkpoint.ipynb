{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f97a4ea1-f592-415c-b368-5aa9a85227fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analisando UFT...\n",
      "\n",
      "Gerando modelos nulos...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gerando modelos nulos:  50%|████████████████████████████████████████████▌                                            | 5/10 [1:57:23<1:57:23, 1408.72s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 248\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;66;03m# Analisa cada instituição\u001b[39;00m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m instituicao \u001b[38;5;129;01min\u001b[39;00m INSTITUICOES:\n\u001b[0;32m--> 248\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43manalyze_institution\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstituicao\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    250\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m results \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    251\u001b[0m         analysis_results[instituicao] \u001b[38;5;241m=\u001b[39m results\n",
      "Cell \u001b[0;32mIn[6], line 203\u001b[0m, in \u001b[0;36manalyze_institution\u001b[0;34m(institution, year, save_dir)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;66;03m# Gera modelos nulos usando o grafo real como referência\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mGerando modelos nulos...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 203\u001b[0m null_stats \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_null_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG_real\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;66;03m# Calcula métrica de Small-Worldness\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mCalculando Small-Worldness...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[6], line 81\u001b[0m, in \u001b[0;36mgenerate_null_models\u001b[0;34m(real_graph, num_simulations)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     80\u001b[0m     cc_rand \u001b[38;5;241m=\u001b[39m nx\u001b[38;5;241m.\u001b[39maverage_clustering(G_rand)\n\u001b[0;32m---> 81\u001b[0m     mc_rand \u001b[38;5;241m=\u001b[39m \u001b[43mnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maverage_shortest_path_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG_rand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m     cc_rand_list\u001b[38;5;241m.\u001b[39mappend(cc_rand)\n\u001b[1;32m     83\u001b[0m     mc_rand_list\u001b[38;5;241m.\u001b[39mappend(mc_rand)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/site-packages/networkx/utils/backends.py:412\u001b[0m, in \u001b[0;36m_dispatch.__call__\u001b[0;34m(self, backend, *args, **kwargs)\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39margs, backend\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    410\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m backends:\n\u001b[1;32m    411\u001b[0m         \u001b[38;5;66;03m# Fast path if no backends are installed\u001b[39;00m\n\u001b[0;32m--> 412\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43morig_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    414\u001b[0m     \u001b[38;5;66;03m# Use `backend_name` in this function instead of `backend`\u001b[39;00m\n\u001b[1;32m    415\u001b[0m     backend_name \u001b[38;5;241m=\u001b[39m backend\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/site-packages/networkx/algorithms/shortest_paths/generic.py:432\u001b[0m, in \u001b[0;36maverage_shortest_path_length\u001b[0;34m(G, weight, method)\u001b[0m\n\u001b[1;32m    428\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m nx\u001b[38;5;241m.\u001b[39msingle_source_bellman_ford_path_length(G, v, weight\u001b[38;5;241m=\u001b[39mweight)\n\u001b[1;32m    430\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01min\u001b[39;00m single_source_methods:\n\u001b[1;32m    431\u001b[0m     \u001b[38;5;66;03m# Sum the distances for each (ordered) pair of source and target node.\u001b[39;00m\n\u001b[0;32m--> 432\u001b[0m     s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(l \u001b[38;5;28;01mfor\u001b[39;00m u \u001b[38;5;129;01min\u001b[39;00m G \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m path_length(u)\u001b[38;5;241m.\u001b[39mvalues())\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    434\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloyd-warshall\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/site-packages/networkx/algorithms/shortest_paths/generic.py:432\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    428\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m nx\u001b[38;5;241m.\u001b[39msingle_source_bellman_ford_path_length(G, v, weight\u001b[38;5;241m=\u001b[39mweight)\n\u001b[1;32m    430\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01min\u001b[39;00m single_source_methods:\n\u001b[1;32m    431\u001b[0m     \u001b[38;5;66;03m# Sum the distances for each (ordered) pair of source and target node.\u001b[39;00m\n\u001b[0;32m--> 432\u001b[0m     s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(l \u001b[38;5;28;01mfor\u001b[39;00m u \u001b[38;5;129;01min\u001b[39;00m G \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m \u001b[43mpath_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43mu\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mvalues())\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    434\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloyd-warshall\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/site-packages/networkx/algorithms/shortest_paths/generic.py:424\u001b[0m, in \u001b[0;36maverage_shortest_path_length.<locals>.path_length\u001b[0;34m(v)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpath_length\u001b[39m(v):\n\u001b[1;32m    423\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munweighted\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 424\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msingle_source_shortest_path_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    425\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdijkstra\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    426\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m nx\u001b[38;5;241m.\u001b[39msingle_source_dijkstra_path_length(G, v, weight\u001b[38;5;241m=\u001b[39mweight)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/site-packages/networkx/utils/backends.py:412\u001b[0m, in \u001b[0;36m_dispatch.__call__\u001b[0;34m(self, backend, *args, **kwargs)\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39margs, backend\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    410\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m backends:\n\u001b[1;32m    411\u001b[0m         \u001b[38;5;66;03m# Fast path if no backends are installed\u001b[39;00m\n\u001b[0;32m--> 412\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43morig_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    414\u001b[0m     \u001b[38;5;66;03m# Use `backend_name` in this function instead of `backend`\u001b[39;00m\n\u001b[1;32m    415\u001b[0m     backend_name \u001b[38;5;241m=\u001b[39m backend\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/site-packages/networkx/algorithms/shortest_paths/unweighted.py:62\u001b[0m, in \u001b[0;36msingle_source_shortest_path_length\u001b[0;34m(G, source, cutoff)\u001b[0m\n\u001b[1;32m     60\u001b[0m     cutoff \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     61\u001b[0m nextlevel \u001b[38;5;241m=\u001b[39m [source]\n\u001b[0;32m---> 62\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mdict\u001b[39m(_single_shortest_path_length(G\u001b[38;5;241m.\u001b[39m_adj, nextlevel, cutoff))\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/site-packages/networkx/algorithms/shortest_paths/unweighted.py:91\u001b[0m, in \u001b[0;36m_single_shortest_path_length\u001b[0;34m(adj, firstlevel, cutoff)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m adj[v]:\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m w \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m seen:\n\u001b[0;32m---> 91\u001b[0m         seen\u001b[38;5;241m.\u001b[39madd(w)\n\u001b[1;32m     92\u001b[0m         nextlevel\u001b[38;5;241m.\u001b[39mappend(w)\n\u001b[1;32m     93\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m (w, level)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "import os\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import pickle\n",
    "\n",
    "# Configurações\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_theme(style=\"whitegrid\", font='serif', rc={'font.serif': ['Times New Roman']})\n",
    "sns.set_context(\"talk\")\n",
    "\n",
    "INSTITUICOES = ['uft', 'ufnt', 'ceulp', 'ifto', 'unitins', 'tocantins']\n",
    "\n",
    "def load_network_data(institution, year):\n",
    "    \"\"\"Carrega os dados da rede a partir do arquivo JSON\"\"\"\n",
    "    file_path = f'../results/metrics/{institution}/{institution}_{year}.json'\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "def load_real_graph(institution, year):\n",
    "    \"\"\"Carrega o grafo real a partir do arquivo GEXF e retorna o maior componente conexo\"\"\"\n",
    "    file_path = f'../results/graphs/{institution}/graph_{institution}_{year}.gexf'\n",
    "    G = nx.read_gexf(file_path)\n",
    "    \n",
    "    # Verifica se o grafo é conexo\n",
    "    if not nx.is_connected(G):\n",
    "        # Obtém o maior componente conexo\n",
    "        largest_cc = max(nx.connected_components(G), key=len)\n",
    "        G = G.subgraph(largest_cc).copy()\n",
    "        \n",
    "    return G\n",
    "\n",
    "def save_null_models(null_stats, institution, year, save_dir):\n",
    "    \"\"\"Salva os modelos nulos e suas métricas em arquivos\"\"\"\n",
    "    os.makedirs(f\"{save_dir}/{institution}\", exist_ok=True)\n",
    "    \n",
    "    # Salva as métricas\n",
    "    metrics_path = f\"{save_dir}/{institution}/null_metrics_{institution}_{year}.pkl\"\n",
    "    with open(metrics_path, 'wb') as f:\n",
    "        pickle.dump(null_stats, f)\n",
    "    \n",
    "    print(f\"Modelos nulos e métricas salvos em {save_dir}/{institution}/\")\n",
    "\n",
    "def load_null_models(institution, year, save_dir):\n",
    "    \"\"\"Carrega os modelos nulos e suas métricas de arquivos\"\"\"\n",
    "    metrics_path = f\"{save_dir}/{institution}/null_metrics_{institution}_{year}.pkl\"\n",
    "    \n",
    "    if os.path.exists(metrics_path):\n",
    "        with open(metrics_path, 'rb') as f:\n",
    "            null_stats = pickle.load(f)\n",
    "        print(f\"Modelos nulos carregados de {metrics_path}\")\n",
    "        return null_stats\n",
    "    else:\n",
    "        print(f\"Nenhum modelo nulo encontrado em {metrics_path}\")\n",
    "        return None\n",
    "\n",
    "def generate_null_models(real_graph, num_simulations=10):\n",
    "    \"\"\"\n",
    "    Gera modelos nulos para comparação usando apenas o maior componente conexo:\n",
    "    1. Modelo Erdos-Renyi (mesmo número de nós e arestas)\n",
    "    2. Modelo de Configuração (mesma distribuição de grau)\n",
    "    \"\"\"\n",
    "    n = real_graph.number_of_nodes()\n",
    "    m = real_graph.number_of_edges()\n",
    "    \n",
    "    # Inicializa listas para armazenar resultados\n",
    "    cc_rand_list = []\n",
    "    mc_rand_list = []\n",
    "    cc_config_list = []\n",
    "    mc_config_list = []\n",
    "    \n",
    "    for _ in tqdm(range(num_simulations), desc=\"Gerando modelos nulos\"):\n",
    "        # 1. Modelo Erdos-Renyi\n",
    "        G_rand = nx.gnm_random_graph(n, m)\n",
    "        \n",
    "        # Garante que estamos trabalhando com o maior componente conexo\n",
    "        if not nx.is_connected(G_rand):\n",
    "            largest_cc = max(nx.connected_components(G_rand), key=len)\n",
    "            G_rand = G_rand.subgraph(largest_cc).copy()\n",
    "        \n",
    "        # Calcula métricas\n",
    "        try:\n",
    "            cc_rand = nx.average_clustering(G_rand)\n",
    "            mc_rand = nx.average_shortest_path_length(G_rand)\n",
    "            cc_rand_list.append(cc_rand)\n",
    "            mc_rand_list.append(mc_rand)\n",
    "        except nx.NetworkXError as e:\n",
    "            print(f\"Erro no modelo Erdos-Renyi: {str(e)}\")\n",
    "            continue\n",
    "        \n",
    "        # 2. Modelo de Configuração\n",
    "        degree_sequence = [d for n, d in real_graph.degree()]\n",
    "        G_config = nx.configuration_model(degree_sequence)\n",
    "        G_config = nx.Graph(G_config)\n",
    "        G_config.remove_edges_from(nx.selfloop_edges(G_config))\n",
    "        \n",
    "        # Garante que estamos trabalhando com o maior componente conexo\n",
    "        if not nx.is_connected(G_config):\n",
    "            largest_cc = max(nx.connected_components(G_config), key=len)\n",
    "            G_config = G_config.subgraph(largest_cc).copy()\n",
    "        \n",
    "        # Calcula métricas\n",
    "        try:\n",
    "            cc_config = nx.average_clustering(G_config)\n",
    "            mc_config = nx.average_shortest_path_length(G_config)\n",
    "            cc_config_list.append(cc_config)\n",
    "            mc_config_list.append(mc_config)\n",
    "        except nx.NetworkXError as e:\n",
    "            print(f\"Erro no modelo de Configuração: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    # Calcula médias\n",
    "    results = {\n",
    "        'Erdos-Renyi': {\n",
    "            'avg_clustering': np.mean(cc_rand_list) if cc_rand_list else np.nan,\n",
    "            'avg_path_length': np.mean(mc_rand_list) if mc_rand_list else np.nan,\n",
    "            'std_clustering': np.std(cc_rand_list) if cc_rand_list else np.nan,\n",
    "            'std_path_length': np.std(mc_rand_list) if mc_rand_list else np.nan\n",
    "        },\n",
    "        'Configuration': {\n",
    "            'avg_clustering': np.mean(cc_config_list) if cc_config_list else np.nan,\n",
    "            'avg_path_length': np.mean(mc_config_list) if mc_config_list else np.nan,\n",
    "            'std_clustering': np.std(cc_config_list) if cc_config_list else np.nan,\n",
    "            'std_path_length': np.std(mc_config_list) if mc_config_list else np.nan\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "def calculate_small_worldness(real_cc, real_mc, rand_cc, rand_mc, config_cc=None, config_mc=None):\n",
    "    \"\"\"\n",
    "    Calcula a métrica de Small-Worldness de Humphries & Gurney\n",
    "    \"\"\"\n",
    "    if rand_cc == 0 or rand_mc == 0:\n",
    "        return np.nan\n",
    "    \n",
    "    S = (real_cc / rand_cc) / (real_mc / rand_mc)\n",
    "    \n",
    "    S_config = np.nan\n",
    "    if config_cc is not None and config_mc is not None and config_cc != 0 and config_mc != 0:\n",
    "        S_config = (real_cc / config_cc) / (real_mc / config_mc)\n",
    "    \n",
    "    return {\n",
    "        'Small-Worldness (vs ER)': S,\n",
    "        'Small-Worldness (vs Config)': S_config\n",
    "    }\n",
    "\n",
    "def plot_comparison(institution, real_stats, null_stats, save_dir=None):\n",
    "    \"\"\"Plota a comparação entre a rede real e os modelos nulos\"\"\"\n",
    "    models = ['Real', 'Erdos-Renyi', 'Configuration']\n",
    "    cc_values = [real_stats['avg_clustering'], \n",
    "                 null_stats['Erdos-Renyi']['avg_clustering'], \n",
    "                 null_stats['Configuration']['avg_clustering']]\n",
    "    cc_errors = [0, \n",
    "                 null_stats['Erdos-Renyi']['std_clustering'], \n",
    "                 null_stats['Configuration']['std_clustering']]\n",
    "    \n",
    "    mc_values = [real_stats['avg_path_length'], \n",
    "                 null_stats['Erdos-Renyi']['avg_path_length'], \n",
    "                 null_stats['Configuration']['avg_path_length']]\n",
    "    mc_errors = [0, \n",
    "                 null_stats['Erdos-Renyi']['std_path_length'], \n",
    "                 null_stats['Configuration']['std_path_length']]\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))\n",
    "    \n",
    "    ax1.bar(models, cc_values, yerr=cc_errors, capsize=10, color=['#1f77b4', '#ff7f0e', '#2ca02c'])\n",
    "    ax1.set_title(f'Coeficiente de Agrupamento Médio - {institution.upper()}', fontsize=16)\n",
    "    ax1.set_ylabel('Valor Médio', fontsize=14)\n",
    "    ax1.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    ax2.bar(models, mc_values, yerr=mc_errors, capsize=10, color=['#1f77b4', '#ff7f0e', '#2ca02c'])\n",
    "    ax2.set_title(f'Caminho Médio Mais Curto - {institution.upper()}', fontsize=16)\n",
    "    ax2.set_ylabel('Valor Médio', fontsize=14)\n",
    "    ax2.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_dir:\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        save_path = Path(f'{save_dir}/{institution}/') / f'{institution}_null_models_comparison.png'\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "def analyze_institution(institution, year='2024', save_dir=None, load_existing=False):\n",
    "    \"\"\"Realiza toda a análise para uma instituição\"\"\"\n",
    "    print(f\"\\nAnalisando {institution.upper()}...\")\n",
    "    \n",
    "    try:\n",
    "        # Carrega os dados do JSON\n",
    "        data = load_network_data(institution, year)\n",
    "        \n",
    "        # Carrega o grafo real (já retorna o maior componente conexo)\n",
    "        G_real = load_real_graph(institution, year)\n",
    "        \n",
    "        # Obtém estatísticas da rede real\n",
    "        real_stats = {\n",
    "            'avg_clustering': data['average_clustering_coefficient'],\n",
    "            'avg_path_length': data['average_shortest_path_length']\n",
    "        }\n",
    "        \n",
    "        # Verifica se deve carregar modelos existentes\n",
    "        null_stats = None\n",
    "        if load_existing and save_dir:\n",
    "            null_stats = load_null_models(institution, year, save_dir)\n",
    "        \n",
    "        # Se não carregou modelos existentes, gera novos\n",
    "        if null_stats is None:\n",
    "            print(f\"\\nGerando modelos nulos...\")\n",
    "            null_stats = generate_null_models(G_real)\n",
    "            \n",
    "            # Salva os modelos nulos gerados\n",
    "            if save_dir:\n",
    "                save_null_models(null_stats, institution, year, save_dir)\n",
    "        \n",
    "        # Calcula métrica de Small-Worldness\n",
    "        print(f\"\\nCalculando Small-Worldness...\")\n",
    "        small_worldness = calculate_small_worldness(\n",
    "            real_stats['avg_clustering'],\n",
    "            real_stats['avg_path_length'],\n",
    "            null_stats['Erdos-Renyi']['avg_clustering'],\n",
    "            null_stats['Erdos-Renyi']['avg_path_length'],\n",
    "            null_stats['Configuration']['avg_clustering'],\n",
    "            null_stats['Configuration']['avg_path_length']\n",
    "        )\n",
    "        \n",
    "        # Plota comparação\n",
    "        plot_comparison(institution, real_stats, null_stats, save_dir)\n",
    "        \n",
    "        # Prepara resultados para exibição\n",
    "        results = {\n",
    "            'Rede Real': real_stats,\n",
    "            'Modelos Nulos': null_stats,\n",
    "            'Small-Worldness': small_worldness,\n",
    "            'Network Stats': {\n",
    "                'Número de Nós': G_real.number_of_nodes(),\n",
    "                'Número de Arestas': G_real.number_of_edges(),\n",
    "                'Grau Médio': sum(dict(G_real.degree()).values()) / G_real.number_of_nodes(),\n",
    "                'Densidade': nx.density(G_real),\n",
    "                'Componente Conexo': \"Maior componente\" if not nx.is_connected(load_real_graph(institution, year)) else \"Grafo conexo\"\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao analisar {institution}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Diretório para salvar os resultados\n",
    "save_dir = \"../results/img/null_models_comparison/\".strip()\n",
    "null_models_dir = \"../results/null_models/\"  # Novo diretório para salvar os modelos nulos\n",
    "\n",
    "analysis_results = {}\n",
    "\n",
    "# Cria os diretórios se não existirem\n",
    "for directory in [save_dir, null_models_dir]:\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "# Pergunta ao usuário se deseja carregar modelos existentes\n",
    "load_existing = input(\"Deseja carregar modelos nulos existentes? (s/n): \").lower() == 's'\n",
    "\n",
    "# Analisa cada instituição\n",
    "for instituicao in INSTITUICOES:\n",
    "    results = analyze_institution(instituicao, save_dir=save_dir, load_existing=load_existing)\n",
    "    \n",
    "    if results is not None:\n",
    "        analysis_results[instituicao] = results\n",
    "        \n",
    "        # Exibe resultados\n",
    "        print(f\"\\nResultados para {instituicao.upper()}:\")\n",
    "        \n",
    "        print(\"\\nEstatísticas da Rede:\")\n",
    "        print(f\"- Número de Nós: {results['Network Stats']['Número de Nós']}\")\n",
    "        print(f\"- Número de Arestas: {results['Network Stats']['Número de Arestas']}\")\n",
    "        print(f\"- Grau Médio: {results['Network Stats']['Grau Médio']:.2f}\")\n",
    "        print(f\"- Densidade: {results['Network Stats']['Densidade']:.4f}\")\n",
    "        print(f\"- Componente Conexo: {results['Network Stats']['Componente Conexo']}\")\n",
    "        \n",
    "        print(\"\\nMétricas da Rede Real:\")\n",
    "        print(f\"- Coeficiente de Agrupamento Médio: {results['Rede Real']['avg_clustering']:.4f}\")\n",
    "        print(f\"- Caminho Médio Mais Curto: {results['Rede Real']['avg_path_length']:.4f}\")\n",
    "        \n",
    "        print(\"\\nComparação com Modelos Nulos:\")\n",
    "        print(\"Erdos-Renyi:\")\n",
    "        print(f\"- Coeficiente de Agrupamento Médio: {results['Modelos Nulos']['Erdos-Renyi']['avg_clustering']:.4f} ± {results['Modelos Nulos']['Erdos-Renyi']['std_clustering']:.4f}\")\n",
    "        print(f\"- Caminho Médio Mais Curto: {results['Modelos Nulos']['Erdos-Renyi']['avg_path_length']:.4f} ± {results['Modelos Nulos']['Erdos-Renyi']['std_path_length']:.4f}\")\n",
    "        \n",
    "        print(\"\\nConfiguration Model:\")\n",
    "        print(f\"- Coeficiente de Agrupamento Médio: {results['Modelos Nulos']['Configuration']['avg_clustering']:.4f} ± {results['Modelos Nulos']['Configuration']['std_clustering']:.4f}\")\n",
    "        print(f\"- Caminho Médio Mais Curto: {results['Modelos Nulos']['Configuration']['avg_path_length']:.4f} ± {results['Modelos Nulos']['Configuration']['std_path_length']:.4f}\")\n",
    "        \n",
    "        print(\"\\nSmall-Worldness:\")\n",
    "        print(f\"- vs Erdos-Renyi: {results['Small-Worldness']['Small-Worldness (vs ER)']:.4f}\")\n",
    "        print(f\"- vs Configuration Model: {results['Small-Worldness']['Small-Worldness (vs Config)']:.4f}\")\n",
    "\n",
    "print(\"\\nAnálise concluída!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a08661-c716-4762-87af-bfb9d7160d58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "networks_tocantins",
   "language": "python",
   "name": "networks_tocantins"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
